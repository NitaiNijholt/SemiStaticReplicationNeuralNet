{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths and correlation generating functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_correlated_gbm(\n",
    "    S0,\n",
    "    r,\n",
    "    q,\n",
    "    sigma,\n",
    "    corr_matrix,\n",
    "    T,\n",
    "    n_steps,\n",
    "    n_sims=1,\n",
    "    random_seed=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Simulates correlated GBM paths for multiple assets that each pay a continuous\n",
    "    dividend yield q[i]. Under the risk-neutral measure, the drift becomes (r - q[i])\n",
    "    for the i-th asset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    S0 : array-like of shape (n_assets,)\n",
    "        Initial prices of the assets.\n",
    "    r : float\n",
    "        Risk-free interest rate (annualized).\n",
    "    q : array-like of shape (n_assets,) or float\n",
    "        Continuous dividend yield(s) for the assets. Can be a single float (applied\n",
    "        to all assets) or an array specifying each asset's q.\n",
    "    sigma : array-like of shape (n_assets,)\n",
    "        Volatilities of the assets.\n",
    "    corr_matrix : 2D array-like of shape (n_assets, n_assets)\n",
    "        Correlation matrix among the assets (must be positive semi-definite).\n",
    "    T : float\n",
    "        Total time horizon for the simulation (in years).\n",
    "    n_steps : int\n",
    "        Number of time steps in the simulation.\n",
    "    n_sims : int, optional\n",
    "        Number of Monte Carlo simulation paths. Default is 1.\n",
    "    random_seed : int, optional\n",
    "        Random seed for reproducibility. Default is None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    paths : ndarray, shape (n_sims, n_assets, n_steps+1)\n",
    "        Simulated price paths for each simulation, for each asset, over the time grid.\n",
    "        The time grid is [0, T], split into n_steps intervals => (n_steps+1) total points.\n",
    "    \"\"\"\n",
    "    # Convert inputs to NumPy arrays\n",
    "    S0 = np.array(S0, dtype=np.float64)\n",
    "    sigma = np.array(sigma, dtype=np.float64)\n",
    "    corr_matrix = np.array(corr_matrix, dtype=np.float64)\n",
    "\n",
    "    n_assets = len(S0)\n",
    "\n",
    "    # If q is a scalar, make it an array of length n_assets\n",
    "    if isinstance(q, (int, float)):\n",
    "        q = np.full(n_assets, float(q))\n",
    "    else:\n",
    "        q = np.array(q, dtype=np.float64)\n",
    "    if q.shape[0] != n_assets:\n",
    "        raise ValueError(\"If 'q' is an array, it must have the same length as 'S0'.\")\n",
    "\n",
    "    # Set the random seed if provided\n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    # Time increment\n",
    "    dt = T / n_steps\n",
    "\n",
    "    # Cholesky decomposition of the correlation matrix\n",
    "    L = np.linalg.cholesky(corr_matrix)\n",
    "\n",
    "    # Pre-allocate the output array\n",
    "    paths = np.zeros((n_sims, n_assets, n_steps + 1))\n",
    "    paths[:, :, 0] = S0  # set initial prices\n",
    "\n",
    "    # For each simulation\n",
    "    for sim_idx in range(n_sims):\n",
    "        for t in range(n_steps):\n",
    "            # Generate independent standard normals\n",
    "            epsilon = np.random.normal(size=n_assets)\n",
    "            # Correlate them\n",
    "            Z = L @ epsilon\n",
    "\n",
    "            # drift_term = (r - q - 0.5 * sigma^2) * dt\n",
    "            drift_term = (r - q - 0.5 * sigma**2) * dt\n",
    "            diffusion_term = sigma * np.sqrt(dt) * Z\n",
    "\n",
    "            # Update each asset price\n",
    "            paths[sim_idx, :, t + 1] = (\n",
    "                paths[sim_idx, :, t] *\n",
    "                np.exp(drift_term + diffusion_term)\n",
    "            )\n",
    "\n",
    "    return paths\n",
    "\n",
    "\n",
    "def build_correlation_matrix(rho, n_assets):\n",
    "    \"\"\"\n",
    "    Returns an n_assets x n_assets correlation matrix with rho off-diagonal and 1 on the diagonal.\n",
    "    \"\"\"\n",
    "    # Create the matrix\n",
    "    corr_matrix = np.full((n_assets, n_assets), rho)  # Fill with rho\n",
    "    np.fill_diagonal(corr_matrix, 1.0)  # Set diagonal to 1.0\n",
    "\n",
    "    return corr_matrix\n",
    "\n",
    "\n",
    "def generate_parameters(n_assets, value=None, mode='same', dist_params=None):\n",
    "    \"\"\"\n",
    "    Generates parameter vectors for `n_assets` based on the specified mode ('same', 'normal', or 'uniform'). \n",
    "    Accepts optional `value` and `dist_params` for customization; raises ValueError for invalid inputs.\n",
    "    \"\"\"\n",
    "    if mode == 'same':\n",
    "        return np.full(n_assets, value)\n",
    "    elif mode == 'normal':\n",
    "        return np.random.normal(loc=value, scale=dist_params['scale'], size=n_assets)\n",
    "    elif mode == 'uniform':\n",
    "        return np.random.uniform(low=dist_params['low'], high=dist_params['high'], size=n_assets)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode. Choose from 'same', 'normal', or 'uniform'.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Payoff function options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def max_among_n_assets_each_date(\n",
    "    n_paths,\n",
    "    style,\n",
    "    strike,\n",
    "    monitoring_dates,\n",
    "    T\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute ONE payoff per monitoring date by taking the maximum price \n",
    "    across 'n_assets' at that date (i.e., each row in n_paths is a single\n",
    "    time dimension, and the columns are the assets).\n",
    "    Returns\n",
    "    -------\n",
    "    payoffs : np.ndarray of shape (num_monitoring_dates,)\n",
    "        A single payoff per monitoring date, computed as:\n",
    "        payoffs[j] = max(0, (max_asset_price_at_t - strike)) [call]\n",
    "        or max(0, (strike - max_asset_price_at_t)) [put].\n",
    "    \"\"\"\n",
    "    # Convert inputs to NumPy arrays\n",
    "    n_paths = np.asarray(n_paths, dtype=float)\n",
    "    monitoring_dates = np.asarray(monitoring_dates, dtype=float)\n",
    "\n",
    "    # Validate shape: for a single scenario with n_assets, we expect 2D\n",
    "    if n_paths.ndim != 2:\n",
    "        raise ValueError(\"n_paths must be 2D: (num_timesteps, n_assets).\")\n",
    "    \n",
    "    num_timesteps, num_assets = n_paths.shape\n",
    "    \n",
    "    # Create a time grid [0, T] with num_timesteps points\n",
    "    time_grid = np.linspace(0, T, num_timesteps)\n",
    "\n",
    "    # For each monitoring date, find the closest index in time_grid\n",
    "    monitoring_indices = [np.argmin(np.abs(time_grid - md)) for md in monitoring_dates]\n",
    "\n",
    "    # Prepare output array: one payoff per monitoring date\n",
    "    payoffs = np.zeros(len(monitoring_indices), dtype=float)\n",
    "\n",
    "    # For each monitoring date...\n",
    "    for j, idx in enumerate(monitoring_indices):\n",
    "        # Take the max among all assets at that time index\n",
    "        max_price = np.max(n_paths[idx, :])\n",
    "\n",
    "        # Compute the payoff for call or put\n",
    "        if style == 'call':\n",
    "            payoff = max(0, max_price - strike)\n",
    "        else:  # 'put'\n",
    "            payoff = max(0, strike - max_price)\n",
    "\n",
    "        payoffs[j] = payoff\n",
    "\n",
    "    return payoffs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def payoff_arithmetic_basket(S, K, option_type, weights=None):\n",
    "    \"\"\"\n",
    "    Computes the payoff of an arithmetic basket call or put option.\n",
    "    Args:\n",
    "        S (ndarray): \n",
    "            2D array of shape (n_sims, n_assets), \n",
    "            where each row represents one path's asset prices \n",
    "            at maturity (or at some time t).\n",
    "        K (float): Strike price of the option.\n",
    "        option_type (str): Either 'call' or 'put'.\n",
    "        weights (ndarray or None): \n",
    "            1D array of shape (n_assets,) indicating the basket weights.\n",
    "            If None, uniform weights are assumed.\n",
    "    Returns:\n",
    "        payoff (ndarray):\n",
    "            1D array of shape (n_sims,); payoff for each path.\n",
    "    \"\"\"\n",
    "    n_sims, n_assets = S.shape\n",
    "\n",
    "    # If weights not provided, assume uniform\n",
    "    if weights is None:\n",
    "        weights = np.ones(n_assets) / n_assets\n",
    "\n",
    "    # 1) Compute weighted sum across the assets = basket price\n",
    "    basket_price = np.sum(S * weights, axis=1)  # shape: (n_sims,)\n",
    "\n",
    "    # 2) Depending on call or put:\n",
    "    if option_type.lower() == 'call':\n",
    "        payoff = np.maximum(basket_price - K, 0.0)\n",
    "    elif option_type.lower() == 'put':\n",
    "        payoff = np.maximum(K - basket_price, 0.0)\n",
    "    else:\n",
    "        raise ValueError(\"option_type must be 'call' or 'put'\")\n",
    "\n",
    "    return payoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is currenly used\n",
    "\n",
    "def payoff_fun(S_t, K, style):\n",
    "    \"\"\"\n",
    "    Computes the payoff from a multi-asset option that depends\n",
    "    on the maximum underlying price among all assets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    S_t : ndarray, shape (n_sims, n_assets)\n",
    "        Asset prices for each simulation at time t.\n",
    "    K : float\n",
    "        Strike price.\n",
    "    style : str\n",
    "        'call' or 'put'.\n",
    "    Returns\n",
    "    -------\n",
    "    payoff : ndarray, shape (n_sims,)\n",
    "        The payoff for each simulation path.\n",
    "    \"\"\"\n",
    "    print(S_t.shape)\n",
    "    # Max price among n_assets\n",
    "    S_max = np.max(S_t, axis=1)\n",
    "    if style.lower() == 'call':\n",
    "        return np.maximum(S_max - K, 0.0)\n",
    "    elif style.lower() == 'put':\n",
    "        return np.maximum(K - S_max, 0.0)\n",
    "    else:\n",
    "        raise ValueError(\"style must be either 'call' or 'put'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RLLN helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Helper Functions for Closed-Form Continuation Value & RLNN\n",
    "\n",
    "\n",
    "def conditional_expectation_closed_form(mu, sigma):\n",
    "    \"\"\"\n",
    "    Computes E[max(X, 0)] for X ~ Normal(mu, sigma^2).\n",
    "\n",
    "    Formula: E[max(X,0)] = sigma * phi(mu/sigma) + mu * Phi(mu/sigma),\n",
    "    where phi and Phi are the standard normal pdf and cdf, respectively.\n",
    "    \"\"\"\n",
    "    if sigma < 1e-14:\n",
    "        # effectively no volatility -> max(mu, 0)\n",
    "        return max(mu, 0.0)\n",
    "\n",
    "    z = mu / sigma\n",
    "    pdf_val = norm.pdf(z)  # phi(z)\n",
    "    cdf_val = norm.cdf(z)  # Phi(z)\n",
    "    return sigma * pdf_val + mu * cdf_val\n",
    "\n",
    "\n",
    "\n",
    "def build_covariance_matrix_dt(sigma_vector, correlation_matrix, dt):\n",
    "    \"\"\"\n",
    "    Build the *log-price* covariance matrix for the time increment dt.\n",
    "      - sigma_vector: shape (d,) -> [sigma_1, ..., sigma_d]\n",
    "      - correlation_matrix: shape (d,d)\n",
    "      - dt: float, (t_m - t_{m-1})\n",
    "    Returns:\n",
    "      covariance_matrix: shape (d,d)\n",
    "    \"\"\"\n",
    "    diag_sigma = np.diag(sigma_vector)            # shape (d, d)\n",
    "    base_cov   = diag_sigma @ correlation_matrix @ diag_sigma  # shape (d, d)\n",
    "    return base_cov * dt\n",
    "\n",
    "\n",
    "def cal_continuation_value_multiasset(\n",
    "    w1, b1, w2, b2,\n",
    "    n_hidden_units,\n",
    "    S_t_prev,        # shape (n_sims, n_assets): raw prices at t_{m-1}\n",
    "    r,\n",
    "    sigma_vector,    # shape (n_assets,)\n",
    "    correlation_mat, # shape (n_assets, n_assets)\n",
    "    dt,\n",
    "    normalizer=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes the continuation value:\n",
    "      Q_{t_{m-1}}(S_t_prev)\n",
    "      = E[ NN(log(S_{t_m})) | S_{t_{m-1}} ] \n",
    "]\n",
    "    Args:\n",
    "        w1 : shape (n_assets, n_hidden_units) - first-layer weights\n",
    "        b1 : shape (n_hidden_units,)         - first-layer biases\n",
    "        w2 : shape (n_hidden_units,) or (n_hidden_units, 1) - second-layer weights\n",
    "        b2 : shape (1,) or float             - output bias\n",
    "        n_hidden_units (int)\n",
    "        S_t_prev : shape (n_sims, n_assets)\n",
    "        r (float) : risk-free rate\n",
    "        sigma_vector : shape (n_assets,)\n",
    "        correlation_mat : shape (n_assets, n_assets)\n",
    "        dt (float): t_m - t_{m-1}\n",
    "        normalizer : If you used normalization, e.g. dividing by S0. \n",
    "                     If None, we assume S_t_prev is actual price.\n",
    "    Returns:\n",
    "        continuation_val : shape (n_sims,) \n",
    "    \"\"\"\n",
    "    n_sims, n_assets = S_t_prev.shape\n",
    "    continuation_val = np.zeros(n_sims)\n",
    "    cov_mat = build_covariance_matrix_dt(sigma_vector, correlation_mat, dt)\n",
    "\n",
    "    if len(w2.shape) == 2 and w2.shape[1] == 1:\n",
    "        w2 = w2.flatten()\n",
    "    if isinstance(b2, np.ndarray) and b2.shape == (1,):\n",
    "        b2 = b2[0]\n",
    "\n",
    "    for i in range(n_sims):\n",
    "        S_n = S_t_prev[i, :] + 1e-14\n",
    "        logS_prev = np.log(S_n)\n",
    "        mu_vec = logS_prev + (r - 0.5*(sigma_vector**2))*dt\n",
    "\n",
    "        nn_sum = 0.0\n",
    "        for neuron_index in range(n_hidden_units):\n",
    "            w1_i = w1.reshape(n_assets, n_hidden_units)[:, neuron_index]\n",
    "            b1_i = b1[neuron_index]\n",
    "            meanZ = np.dot(w1_i, mu_vec)\n",
    "            varZ  = w1_i @ cov_mat @ w1_i\n",
    "            meanZprime = meanZ + b1_i\n",
    "            stdZprime  = np.sqrt(varZ) if varZ > 1e-14 else 0.0\n",
    "            relu_i = conditional_expectation_closed_form(meanZprime, stdZprime)\n",
    "            nn_sum += w2[neuron_index] * relu_i\n",
    "\n",
    "        nn_sum += b2\n",
    "        continuation_val[i] = nn_sum\n",
    "\n",
    "    return continuation_val\n",
    "\n",
    "def create_shallow_NN(input_dim, hidden_units):\n",
    "    \"\"\"\n",
    "    Create a shallow neural network with 1 hidden layer\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): number of nodes in input layer\n",
    "        hidden_units (int): number of nodes in hidden layer\n",
    "\n",
    "    Returns:\n",
    "        model : Neural network model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    # Use Input layer for specifying input shape\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    model.add(Dense(hidden_units, activation='relu', kernel_initializer='random_uniform', bias_initializer= 'random_uniform'))\n",
    "    model.add(Dense(1, activation='linear', kernel_initializer='random_uniform', bias_initializer= 'random_uniform'))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Testing continuation value single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S0 = [100. 100.]\n",
      "mu = [0.05 0.05]\n",
      "sigma_gen = [0.2 0.2]\n",
      "corr_matrix =\n",
      " [[1.  0.3]\n",
      " [0.3 1. ]]\n",
      "----------------------------------------------------------\n",
      "\n",
      "=== Single-Neuron (RLNN) vs. Direct & MC ===\n",
      "Monte Carlo (200k sims) = 7.210421\n",
      "RLNN-style single neuron= 7.210340\n"
     ]
    }
   ],
   "source": [
    " \n",
    "#Generate parameters using the provided functions\n",
    " \n",
    "n_assets = 2\n",
    "rho = 0.3\n",
    "\n",
    "# Generate S0, mu, and sigma\n",
    "S0 = generate_parameters(n_assets, value=100.0, mode='same')\n",
    "mu = generate_parameters(n_assets, value=0.05,  mode='same')  # Not used as \"mu\" in your snippet\n",
    "sigma_gen = generate_parameters(n_assets, value=0.2,  mode='same')  # This yields [0.2, 0.2]\n",
    "\n",
    "# Build correlation matrix\n",
    "corr_matrix = build_correlation_matrix(rho, n_assets)\n",
    "\n",
    "print(\"S0 =\", S0)              \n",
    "print(\"mu =\", mu)             \n",
    "print(\"sigma_gen =\", sigma_gen)\n",
    "print(\"corr_matrix =\\n\", corr_matrix)\n",
    "print(\"----------------------------------------------------------\")\n",
    "\n",
    " \n",
    "# 3) Single-step RLNN test\n",
    "\n",
    "\n",
    "sigma1, sigma2 = sigma_gen \n",
    "d2   = n_assets\n",
    "r2   = 0.02\n",
    "rho2 = 0.3\n",
    "dt2  = 1.0\n",
    "S_tm1_2 = S0\n",
    "\n",
    "logS_tm1_2 = np.log(S_tm1_2)\n",
    "mu2 = np.array([\n",
    "    logS_tm1_2[0] + (r2 - 0.5*sigma1**2)*dt2,\n",
    "    logS_tm1_2[1] + (r2 - 0.5*sigma2**2)*dt2\n",
    "])\n",
    "Sigma2 = np.array([\n",
    "    [sigma1**2,          rho2*sigma1*sigma2],\n",
    "    [rho2*sigma1*sigma2, sigma2**2         ]\n",
    "]) * dt2\n",
    "\n",
    "# (B) Monte Carlo\n",
    "n_sims_mc = 200000\n",
    "rng = np.random.default_rng(123)\n",
    "L2 = np.linalg.cholesky(Sigma2)\n",
    "Z2 = rng.normal(size=(d2, n_sims_mc))\n",
    "logS_m_samples = (L2 @ Z2).T + mu2\n",
    "\n",
    "# Single-neuron parameters\n",
    "w_rlnn = np.array([0.8, 1.2])\n",
    "b_rlnn = -2.0\n",
    "\n",
    "Y_sims = logS_m_samples @ w_rlnn + b_rlnn\n",
    "mc_payoff = np.maximum(Y_sims, 0.0)\n",
    "mc_value_2 = mc_payoff.mean()\n",
    "\n",
    "\n",
    "# We'll tile the same S_tm1_2 into an array, so all s0 are same => shape (n_sims_test, d2)\n",
    "n_sims_test = 5000\n",
    "S_tm1_array = np.tile(S_tm1_2, (n_sims_test, 1))\n",
    "\n",
    "w1_matrix = w_rlnn.reshape(d2, 1)  # shape (2,1)\n",
    "b1_array  = np.array([b_rlnn])     # shape (1,)\n",
    "w2_array  = np.array([1.0])        # second-layer weight = 1\n",
    "b2_scalar = 0.0                    # output bias = 0\n",
    "\n",
    "rlnn_vals = cal_continuation_value_multiasset(\n",
    "    w1_matrix, b1_array, w2_array, b2_scalar,\n",
    "    n_hidden_units=1,\n",
    "    S_t_prev=S_tm1_array,\n",
    "    r=r2,\n",
    "    sigma_vector=sigma_gen,\n",
    "    correlation_mat=corr_matrix, \n",
    "    dt=dt2\n",
    ")\n",
    "\n",
    "rlnn_val_single = rlnn_vals[0]\n",
    "\n",
    "print(\"\\n=== Single-Neuron (RLNN) vs. Direct & MC ===\")\n",
    "print(f\"Monte Carlo (200k sims) = {mc_value_2:.6f}\")\n",
    "print(f\"RLNN-style single neuron= {rlnn_val_single:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main RLNN_Algo for Multi-Asset with Log-Price & Closed-Form Continuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RLNN_Algo_multiasset(\n",
    "    n_assets, S0, K, r, q, vol, rho, \n",
    "    sample_size, n_steps, no_mon, T, style, \n",
    "    no_hidden_units, l_rate,\n",
    "    build_correlation_matrix,\n",
    "    generate_parameters,\n",
    "    simulate_correlated_gbm,\n",
    "    payoff_fun,\n",
    "    create_shallow_NN\n",
    "):\n",
    "    \"\"\"\n",
    "    Multi-Asset RLNN with closed form continuation value\n",
    "    based on log-prices.\n",
    "\n",
    "    Args:\n",
    "        n_assets (int): number of assets\n",
    "        S0 (float): initial price (if same across assets)\n",
    "        K (float): strike\n",
    "        r (float): risk-free rate\n",
    "        q (float): div yield\n",
    "        vol (float): base volatility\n",
    "        rho (float): correlation param\n",
    "        sample_size (int): number of MC paths\n",
    "        n_steps (int): total time steps\n",
    "        no_mon (int): number of monitoring points\n",
    "        T (float): maturity\n",
    "        style (str): 'call'/'put'\n",
    "        no_hidden_units (int): hidden layer size\n",
    "        l_rate (float): learning rate\n",
    "\n",
    "        build_correlation_matrix (func): user-provided\n",
    "        generate_parameters (func): user-provided\n",
    "        simulate_correlated_gbm (func): user-provided\n",
    "        payoff_fun (func): payoff for multi-asset\n",
    "        create_shallow_NN (func): returns a Keras model\n",
    "\n",
    "    Returns:\n",
    "        (approx_value_t0, weights_list, errors_list)\n",
    "    \"\"\"\n",
    "\n",
    "    # For storing neural net weights at each step, plus training errors\n",
    "    weights = []\n",
    "    errors = []\n",
    "\n",
    "    # 1) Build correlation & simulate\n",
    "    corr_matrix = build_correlation_matrix(rho, n_assets)   # shape (n_assets, n_assets)\n",
    "\n",
    "    S0_vec    = generate_parameters(n_assets, value=S0,  mode='same') \n",
    "    sigma_vec = generate_parameters(n_assets, value=vol,   mode='same')\n",
    "\n",
    "    # shape => (n_sims, n_assets, n_steps+1)\n",
    "    stock_paths = simulate_correlated_gbm(\n",
    "        S0_vec, r, q, sigma_vec, corr_matrix, \n",
    "        T, n_steps, n_sims=sample_size, random_seed=None\n",
    "    )\n",
    "\n",
    "    # 2) Initialize array for option values\n",
    "    option_price = np.zeros((sample_size, n_steps+1))\n",
    "\n",
    "    # 3) Compute payoff at maturity\n",
    "    payoff_T = payoff_fun(stock_paths[:, :, n_steps], K, style)  # shape (n_sims,)\n",
    "    option_price[:, n_steps] = payoff_T\n",
    "\n",
    "    # 4) Pre-train a shallow NN at final time\n",
    "    model = create_shallow_NN(n_assets, no_hidden_units)\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(l_rate))\n",
    "\n",
    "    X_final = np.log(stock_paths[:, :, n_steps] + 1e-14)  # log-prices\n",
    "    y_final = payoff_T\n",
    "\n",
    "    model.fit(\n",
    "        X_final, y_final,\n",
    "        epochs=1000,\n",
    "        batch_size=int(0.1 * sample_size),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Evaluate final-time MSE:\n",
    "    y_pred_final = model.predict(X_final).flatten()\n",
    "    final_mse = np.mean((y_pred_final - y_final)**2)\n",
    "    errors.append(final_mse)\n",
    "\n",
    "    # Move backwards in time \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss', mode='min',\n",
    "        patience=20, restore_best_weights=True,\n",
    "        start_from_epoch=100\n",
    "    )\n",
    "\n",
    "    for m in range(n_steps-1, -1, -1):\n",
    "        # Train \n",
    "        X_m = np.log(stock_paths[:, :, m] + 1e-14)   # shape (n_sims, n_assets)\n",
    "        y_m = option_price[:, m]                    # shape (n_sims,)\n",
    "\n",
    "        # Split data for validation\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_m, y_m, test_size=0.2\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=1000,\n",
    "            batch_size=int(0.1 * X_train.shape[0]),\n",
    "            validation_data=(X_test, y_test),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Evaluate MSE for logging\n",
    "        y_hat_test = model.predict(X_test).flatten()\n",
    "        test_mse = np.mean((y_hat_test - y_test)**2)\n",
    "        errors.append(test_mse)\n",
    "\n",
    "        #  Extract NN weights\n",
    "        # shape of first layer weights: (n_assets, n_hidden_units)\n",
    "        w1_ = model.layers[0].get_weights()[0]\n",
    "        b1_ = model.layers[0].get_weights()[1]\n",
    "        w2_ = model.layers[1].get_weights()[0]\n",
    "        b2_ = model.layers[1].get_weights()[1]\n",
    "        weights.append(model.get_weights())\n",
    "\n",
    "        # If m>0, compute continuation at time m-1:\n",
    "        if m > 0:\n",
    "            S_mminus1 = stock_paths[:, :, m-1]  # shape (n_sims, n_assets)\n",
    "            fun_h     = payoff_fun(S_mminus1, K, style)   # shape (n_sims,)\n",
    "\n",
    "            dt = (T / n_steps) \n",
    "\n",
    "            # closed-form expectation\n",
    "            cont_val = cal_continuation_value_multiasset(\n",
    "                w1_, b1_, w2_, b2_,\n",
    "                no_hidden_units,\n",
    "                S_mminus1,    #  price at time (m-1)\n",
    "                r,           \n",
    "                sigma_vec,\n",
    "                corr_matrix,\n",
    "                dt,\n",
    "                normalizer=None \n",
    "            )\n",
    "\n",
    "            # final\n",
    "            option_price[:, m-1] = np.maximum(fun_h, cont_val)\n",
    "\n",
    "    # Return approximate value at t0, plus weights and errors\n",
    "    return option_price[:, 0].mean(), weights, errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 3)\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737us/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "(20000, 3)\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step\n",
      "Estimated Option Value at t0: 10.9832\n",
      "Final training errors_list: [np.float64(23.107921569744647), np.float64(2.3726878384750327e-46), np.float64(22.15189059429035), np.float64(17.393758508858163), np.float64(12.967564607534193), np.float64(10.190643928167654), np.float64(8.031180730287955), np.float64(6.673180460785116), np.float64(6.1788191567236765), np.float64(5.896425671517022), np.float64(4.578272006783669), np.float64(3.379598263372657), np.float64(3.049571674824636), np.float64(2.6616597879867006), np.float64(2.5409084053728574), np.float64(1.8271274264456365), np.float64(1.579834072087896), np.float64(0.9930799190407965), np.float64(0.8159755847619296), np.float64(0.728954404968778), np.float64(0.5362662209382436), np.float64(0.3640325622462167), np.float64(0.37237242329212406), np.float64(0.14080696697842632), np.float64(0.13073422945105556), np.float64(0.059153354652689394), np.float64(0.03113163133317844), np.float64(0.02996102807388281), np.float64(0.0021055178580760858), np.float64(0.0), np.float64(1.4551915228366852e-11)]\n"
     ]
    }
   ],
   "source": [
    "n_assets     = 3\n",
    "S0           = 100.0\n",
    "K            = 100.0\n",
    "r            = 0.05\n",
    "q            = 0.00\n",
    "vol          = 0.2\n",
    "rho          = 0.5 \n",
    "sample_size  = 20000\n",
    "n_steps      = 30\n",
    "no_mon       = 4     # passed, but unused in RLNN_Algo_multiasset currently. Left it for when we reimplement Bermudan options\n",
    "T            = 1.0   # maturity = 1 year\n",
    "style        = \"put\"\n",
    "no_hidden_units = 16\n",
    "l_rate       = 0.05\n",
    "\n",
    "# Call the RLNN solver\n",
    "approx_value_t0, weights_list, errors_list = RLNN_Algo_multiasset(\n",
    "    n_assets, S0, K, r, q, vol, rho,\n",
    "    sample_size, n_steps, no_mon, T, style,\n",
    "    no_hidden_units, l_rate,\n",
    "    build_correlation_matrix,\n",
    "    generate_parameters,\n",
    "    simulate_correlated_gbm,\n",
    "    payoff_fun,\n",
    "    create_shallow_NN\n",
    ")\n",
    "\n",
    "print(f\"Estimated Option Value at t0: {approx_value_t0:.4f}\")\n",
    "print(\"Final training errors_list:\", errors_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "General",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
